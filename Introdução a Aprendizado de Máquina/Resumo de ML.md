# 1. Aprendizado de M√°quina
Aprender √© o processo pelo qual um sistema melhora seu desempenho por meio da experi√™ncia. O Aprendizado de M√°quina (Machine Learning) surge como uma solu√ß√£o para problemas onde √© dif√≠cil antecipar todas as situa√ß√µes poss√≠veis ou programar uma solu√ß√£o passo a passo. As abordagens para o aprendizado incluem:

- **Aprendizado como busca**: Consiste em enumerar um espa√ßo de conceitos e eliminar aqueles que n√£o condizem com os dados observados.
    
- **Aprendizado indutivo**: Foca em extrair informa√ß√µes gerais a partir da observa√ß√£o de um conjunto de casos particulares. Um exemplo hist√≥rico √© como as observa√ß√µes de Tycho Brahe permitiram a Johannes Kepler formular suas leis da mec√¢nica celeste.
    
### O Papel dos Dados

Os dados s√£o a base para o treinamento de programas de aprendizado de m√°quina. O desenvolvimento de um sistema de ML segue etapas como a defini√ß√£o do problema, coleta e prepara√ß√£o dos dados, treinamento e avalia√ß√£o do modelo.

Contudo, a coleta de dados apresenta desafios:

- **Desbalanceamento**: Fontes como a Wikipedia possuem uma distribui√ß√£o de t√≥picos desigual, com maior concentra√ß√£o em √°reas como Esportes, M√∫sica e Pol√≠tica.
    
- **Falta de Diversidade**: Os dados frequentemente sub-representam diversas culturas, geografias e grupos √©tnicos , privilegiando pontos de vista predominantes. O acesso √† internet, por exemplo, √© maior entre jovens e em pa√≠ses desenvolvidos.
    
- **Dados no Brasil**: Embora o acesso √† internet atinja 80% dos domic√≠lios, h√° uma disparidade social: 100% da classe A est√° conectada, contra 60% das classes D e E.
### Rela√ß√£o com Outras √Åreas

O documento posiciona o Aprendizado de M√°quina dentro de um contexto mais amplo:

- **Intelig√™ncia Artificial (IA)**: √â a √°rea mais ampla, focada na constru√ß√£o de sistemas inteligentes que se comportam como humanos.
    
- **Aprendizado de M√°quina (ML)**: √â uma sub√°rea da IA que desenvolve algoritmos capazes de aprender.
    
- **Aprendizado Profundo (Deep Learning)**: Uma sub√°rea do ML que utiliza modelos com m√∫ltiplas camadas de processamento para aprender representa√ß√µes de dados em v√°rios n√≠veis de abstra√ß√£o.
    
- **Ci√™ncia de Dados e Minera√ß√£o de Dados**: A Ci√™ncia de Dados estuda a extra√ß√£o de conhecimento a partir de dados, utilizando t√©cnicas de ML , enquanto a Minera√ß√£o de Dados foca na aplica√ß√£o de algoritmos para extrair padr√µes de conjuntos de dados.
# 2. Perceptron

Ele √© o **modelo mais simples de rede neural** e foi o ponto de partida para o desenvolvimento do **aprendizado supervisionado**.

- Objetivo: **Classificar** dados em duas classes (ex: 0 ou 1, -1 ou +1).
    
- Tipo: **Aprendizado supervisionado (classifica√ß√£o bin√°ria)**.
    
- Baseia-se em **combinar entradas ponderadas por pesos** e aplicar uma **fun√ß√£o de ativa√ß√£o**.

O Perceptron representa **um neur√¥nio artificial** com

| Componente                     | Descri√ß√£o                                            |
| ------------------------------ | ---------------------------------------------------- |
| **Entradas (x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)** | Atributos ou vari√°veis de entrada.                   |
| **Pesos (w‚ÇÅ, w‚ÇÇ, ..., w‚Çô)**    | Par√¢metros ajust√°veis (import√¢ncia de cada entrada). |
| **Vi√©s (bias, b)**             | Constante que desloca o limiar da decis√£o.           |
| **Soma Ponderada (z)**         | $z = \sum_{i=1}^{n} (w_i \cdot x_i) + b$             |
| **Fun√ß√£o de Ativa√ß√£o (f)**     | Converte ( z ) em sa√≠da bin√°ria (0 ou 1).            |
Sa√≠da:  
$$
	y =  
    \begin{cases}  
    1, & \text{se } (Œ£_{i=1} w_i x_i + b) > 0 \\
    0, & \text{caso contr√°rio}  
    \end{cases}  
$$

### üß© Pseudoc√≥digo:

```
Entrada: dados de treino {(x‚ÇÅ, y‚ÇÅ), ..., (x‚Çô, y‚Çô)}
inicializar pesos w_i = 0 e bias b = 0
Definir taxa de aprendizado Œ± (ex: 0.1)

para √©poca em 1..N:
    para cada amostra (x, y_esperado):
        y_pred = ativacao(Œ£(w_i * x_i) + b)
        erro = y_esperado - y_pred
        para cada peso w_i:
            w_i = w_i + Œ± * erro * x_i
        b = b + Œ± * erro
```

**Fun√ß√£o ativa√ß√£o:** retorna 1 se entrada > 0, sen√£o 0.
- **Œ±** ‚Üí taxa de aprendizado (ex: 0.1)
- Atualiza pesos apenas quando h√° erro.
O Perceptron busca **coeficientes (pesos)** que satisfa√ßam:

$$
y_i (w \cdot x_i + b) > 0
$$
para todas as amostras corretamente classificadas.

Se o conjunto for **linearmente separ√°vel**, o Perceptron **converge** (ou seja, encontra pesos corretos).

Se **n√£o for separ√°vel**, ele **n√£o converge** (fica oscilando).

## Representa√ß√£o Geom√©trica

A fronteira de decis√£o √© dada por:

$$
w_1x_1 + w_2x_2 + ... + w_nx_n + b = 0
$$
- Pontos acima ‚Üí classe 1
- Pontos abaixo ‚Üí classe 0

---

## Limita√ß√µes

| Limita√ß√£o                                                  | Explica√ß√£o                                        |
| ---------------------------------------------------------- | ------------------------------------------------- |
| **Somente separ√°vel linearmente**                          | N√£o funciona para padr√µes n√£o lineares (ex: XOR). |
| **Converg√™ncia garantida apenas se linearmente separ√°vel** | Caso contr√°rio, entra em loop.                    |
| **Fun√ß√£o de ativa√ß√£o simples**                             | Apenas degrau; n√£o lida com probabilidades.       |

---

## Vers√£o Vetorial (Forma Compacta)

$$
\begin{matrix}
\mathbf{w} \leftarrow \mathbf{w} + Œ± (y - \hat{y}) \mathbf{x} \\  b \leftarrow b + Œ± (y - \hat{y})
\end{matrix}
$$

- $\mathbf{w}$: vetor de pesos
- $\mathbf{x}$: vetor de entrada
- $y$: r√≥tulo real
- $\hat{y}$‚Äã: previs√£o
## üí° **Dica para Prova**

Lembre-se:
- O perceptron **n√£o ‚Äúentende‚Äù padr√µes curvos** ‚Äî s√≥ retas/planos.
- **Erro = esperado - previsto**
- **Atualiza pesos somente se erra**
- **Bias desloca a fronteira de decis√£o** (n√£o precisa passar pela origem).

#  3. Tipos de Aprendizado

### üîπ Supervisionado:

- Dados **rotulados** (x ‚Üí y conhecidos).
- O modelo **aprende mapeamento f(x) ‚Üí y**.

- Exemplo:
    - Regress√£o linear (previs√£o de valores cont√≠nuos)
    - Classifica√ß√£o (atribui√ß√£o de r√≥tulos, ex: spam/n√£o spam)

#### Como funciona

1. Fornecemos **dados de treino** com pares (entrada, sa√≠da):
$$
  D = \{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\}  
$$
    
2. O modelo aprende **a rela√ß√£o entre x e y** ajustando seus par√¢metros.
3. Depois √© testado em **dados novos** (sem r√≥tulo) para verificar se generalizou bem.
 #### Tipos principais
- **Regress√£o:** Usada para prever valores cont√≠nuos.
- **Classifica√ß√£o:** Utiliza um algoritmo para atribuir dados a categorias espec√≠ficas.

‚ö†Ô∏è Cuidados
- Dividir dataset em **treino e teste**.
- Evitar **overfitting** (memorizar dados).
- Avaliar com m√©tricas adequadas (MSE, acur√°cia, precis√£o, recall...).

---

### üîπ N√£o Supervisionado:

Neste tipo, **os dados n√£o t√™m r√≥tulos** ‚Äî o modelo tenta **descobrir padr√µes, grupos ou estruturas ocultas** nos dados. N√£o h√° ‚Äúresposta correta‚Äù para comparar.

- Dados **n√£o rotulados**.
- O algoritmo descobre **padr√µes ocultos** (grupos, associa√ß√µes).

 Objetivo
- Encontrar **rela√ß√µes internas** entre os dados.
- Reduzir dimensionalidade, agrupar exemplos similares ou identificar outliers.
- Exemplo: _Clustering (agrupamento K-Means)_.

‚ö†Ô∏è Limita√ß√µes
- Dif√≠cil avaliar se o agrupamento est√° ‚Äúcorreto‚Äù.
- Requer interpreta√ß√£o humana posterior.
---

### üîπ Por Refor√ßo:

- O agente aprende por **recompensa/puni√ß√£o** ao interagir com o ambiente.
- Exemplo: jogos, rob√≥tica, controle aut√¥nomo.
    
---

# 4. Modelos Param√©tricos vs. N√£o Param√©tricos

- **Modelos Param√©tricos:** Resumem os dados com um conjunto de par√¢metros de tamanho fixo, independentemente do n√∫mero de exemplos. Exemplos incluem Regress√£o Linear e Perceptron.
    
    - **Vantagens:** S√£o mais f√°ceis de interpretar, mais r√°pidos e n√£o exigem muitos dados.
    - **Desvantagens:** S√£o muito dependentes da fun√ß√£o escolhida e mais adequados para problemas simples.
        
- **Modelos N√£o Param√©tricos:** N√£o podem ser caracterizados por um conjunto limitado de par√¢metros. Exemplos incluem √°rvores de decis√£o, redes neurais e SVM.
    
    - **Vantagens:** S√£o mais flex√≠veis, n√£o fazem suposi√ß√µes sobre a fun√ß√£o subjacente e possuem alta performance.
    - **Desvantagens:** Requerem mais dados, s√£o mais lentos para treinar e t√™m maior risco de _overfitting_.
---

# 5. Tipos de Dados

## Dados Estruturados 

S√£o dados organizados, com informa√ß√µes representadas por atributos (features) e seus valores, geralmente armazenados em bancos de dados ou planilhas. Os tipos de atributos podem ser:

- **Categ√≥ricos/Nominais:** Valores que representam categorias (ex: cor do cabelo).
- **Booleano:** Apenas dois valores (verdadeiro/falso).
- **Ordinal:** Valores que representam uma escala (ex: n√≠vel de satisfa√ß√£o).
- **Num√©ricos:** Valores inteiros ou reais. 

## Dados N√£o Estruturados 
S√£o compostos por diferentes tipos de dados combinados, como textos e imagens.

- **Prepara√ß√£o de Dados:** Textos podem ser convertidos em representa√ß√µes num√©ricas (vetores) para capturar rela√ß√µes sem√¢nticas, como no exemplo `(rei - homem) + mulher = rainha`.
- **Dados de Imagem:** Uma imagem pode ser vista como uma matriz de pixels. Cada pixel √© representado por um valor num√©rico, seja em escala de cinza (um inteiro de 0 a 255) ou RGB (tr√™s inteiros, um para cada cor).

# 6. M√©tricas de Avalia√ß√£o para Modelos

Treinar um modelo (regress√£o, classifica√ß√£o etc.) n√£o √© o suficiente.  
Precisamos **quantificar seu desempenho** ‚Äî ou seja, **medir o erro ou acerto das previs√µes**.

- **Objetivo:** saber se o modelo **generaliza bem** para dados novos.
- **Problema comum:** _Overfitting_ (modelo ‚Äúdecorou‚Äù o treino) ou _Underfitting_ (modelo muito simples)

## Matriz de confus√£o
![[Pasted image 20251008193718.png]]
- **Verdadeiro Positivo (VP):** O modelo previu "positivo" e o valor real era "positivo".
- **Falso Positivo (FP):** O modelo previu "positivo", mas o valor real era "negativo".
- **Falso Negativo (FN):** O modelo previu "negativo", mas o valor real era "positivo".
- **Verdadeiro Negativo (VN):** O modelo previu "negativo" e o valor real era "negativo".

## Acur√°cia
Percentual de acertos totais do modelo. 
Boa quando as classes est√£o **equilibradas**
$$
\text{Acur√°cia }=\frac{VP+VN}{VP+VN+FP+FN}
$$
‚Äã
## Revoca√ß√£o (Recall)
De todos os casos que eram realmente "positivos", quantos o modelo conseguiu identificar?
Alta sensibilidade ‚Üí poucos falsos negativos.
$$
\text{Recall}=\frac{VP}{VP+FN}‚Äã
$$
## Precis√£o
Das vezes que o modelo previu "positivo", quantas ele acertou?
Alta precis√£o ‚Üí poucos falsos positivos.
$$
\text{Precision}=\frac{VP}{VP+FP}‚Äã
$$
## F1 - Score
M√©dia harm√¥nica entre precis√£o e revoca√ß√£o, √∫til para balancear o impacto de falsos positivos e falsos negativos
Boa quando h√° **classes desbalanceadas**.
$$
\text{F1}=2\times \frac{\text{Precis√£o}\times \text{Recall}}{\text{Precis√£o} + \text{Recall}}‚Äã
$$

# 7. Tipos de Dados e Pr√©-Processamento

### Tipos de atributos:

| Tipo         | Exemplo              | Observa√ß√£o                 |
| ------------ | -------------------- | -------------------------- |
| **Nominal**  | Cor (vermelho, azul) | Sem ordem.                 |
| **Bin√°rio**  | Fumante (0/1)        | Dois estados.              |
| **Ordinal**  | Tamanho (P, M, G)    | Ordem, sem dist√¢ncia fixa. |
| **Num√©rico** | Idade, peso          | Intervalo ou raz√£o.        |

---
### Etapas de pr√©-processamento:

1. **Limpeza de dados**
    - Preencher valores ausentes (m√©dia, mediana, modelo preditivo).
    - Remover ru√≠do (m√©todo de _binning_, regress√£o).
    - Detectar outliers.
        
2. **Integra√ß√£o de dados**
    - Unir dados de m√∫ltiplas fontes, resolvendo duplicatas e conflitos de nomes.
        
3. **Redu√ß√£o de dados**
    - Reduzir dimensionalidade (PCA, amostragem, sele√ß√£o de atributos).
        
4. **Transforma√ß√£o de dados**
    - Normalizar (ex: [0,1]).
    - Discretizar (intervalos, faixas de idade etc.).
        
---

### üßÆ Estat√≠stica b√°sica:

#### Medidas de Posi√ß√£o: 
medem a localiza√ß√£o do meio ou centro de uma distribui√ß√£o;

- **M√©dia** (tend√™ncia central)
$$
    \frac{\sum\limits x_i}{n}
$$
sens√≠vel a valores extremos (outliers).

- **Mediana** (valor central)
$$
    \text{mediana }(x) =
 \begin{cases}
 \text{x}_{\frac{n+1}{2}} & \text{se n for √≠mpar} \\
\frac{(\text{x}_{\frac{n}{2}} + \text{x}_{\frac{n+1}{2}})}{2} & \text{se n for par}
 \end{cases}   
$$
para dados assim√©tricos, esta √© a melhor medida.

- **Moda** (valor mais frequente)
#### Medidas de dispers√£o: 
s√£o utilizadas para que possamos saber qual o grau de varia√ß√£o dos nossos dados

- **Quartis**:
	Dividem os dados ordenados em quatro partes iguais. O primeiro quartil (Q1) corresponde ao percentil 25, o segundo (Q2) √© a mediana (percentil 50), e o terceiro (Q3) √© o percentil 75
	
	**Intervalo Interquart√≠lico (IQR):** √â a diferen√ßa entre o terceiro e o primeiro quartil ($IQR=Q3‚àíQ1$), representando a dispers√£o dos 50% centrais dos dados.

	Como calcular os quartis:
$$
\begin{matrix} 
i=(N-1)\cdot q+1
\\
P_{p}=x_{[i]}+(i-[i])\cdot(x_{[i]+1}-x_{[i]})
\end{matrix}
$$
onde:
- 
- 
	Como calcular os limites:
	-  $X_i > LS \text{ (Limite Superior)}$, para $LS=Q_3 + 1.5\times(Q_3-Q_1)$
	- $X_i < LI \text{ (Limite Inferior)}$, para $LI=Q_1 - 1.5\times(Q_3-Q_1)$

- **Vari√¢ncia** $\sigma$= m√©dia dos desvios¬≤ da m√©dia
    $$
    \frac{1}{2}\sum\limits(x_i-\overline{x}_i)^2
$$
- **Desvio padr√£o** = $\sqrt{\sigma}$
    Mede o qu√£o distantes os valores est√£o da m√©dia
- **Z-score** = (valor - m√©dia) / desvio padr√£o ‚Üí mede qu√£o longe est√° da m√©dia.
    $$
    \frac{x-\overline{x}}{\sigma}
$$

---

## üßÆ **4. Regress√£o Linear**

### üìà Modelo:

$$
y = Œ≤_0 + Œ≤_1x + Œµ  

$$
- ( $Œ≤_0$ ): intercepto (valor de y quando x = 0)
    
- ( $Œ≤_1$ ): inclina√ß√£o (quanto y muda quando x varia 1 unidade)
    
- ( $Œµ$ ): erro (diferen√ßa entre previsto e real)
    

**Pseudoc√≥digo (ajuste por m√≠nimos quadrados):**

```
dados = {(x1, y1), ..., (xn, yn)}

Œ≤1 = Cov(x, y) / Var(x)
Œ≤0 = M√©dia(y) - Œ≤1 * M√©dia(x)

para cada novo x:
    prever y_pred = Œ≤0 + Œ≤1 * x
```

### üìä Avalia√ß√£o:

- **Erro Quadr√°tico M√©dio (MSE)**  
$$
MSE = \frac{1}{n}\sum(y_i - \hat{y_i})^2  
$$
    
- Quanto **menor o MSE**, melhor o ajuste.

---

### üîπ Regress√£o Linear M√∫ltipla:
$$
y = Œ≤_0 + Œ≤_1x_1 + Œ≤_2x_2 + ... + Œ≤_nx_n  

$$
- Representa√ß√£o matricial:  
$$
    \mathbf{y} = XŒ≤ + Œµ  
$$    
- Adiciona uma **coluna de 1‚Äôs** para o intercepto.
    

---

## üîó **5. Correla√ß√£o**

### üìè Correla√ß√£o de Pearson:

- Mede **rela√ß√£o linear** entre vari√°veis.  
$$
r = \frac{Cov(x, y)}{œÉ_x œÉ_y}      
$$
- Varia entre **-1 e 1**.
    
    - r = 1 ‚Üí forte positiva
        
    - r = -1 ‚Üí forte negativa
        
    - r ‚âà 0 ‚Üí sem correla√ß√£o linear
        
- **Sens√≠vel a outliers.**
    

---

### üìà Correla√ß√£o de Spearman:

- Usa **ordem (ranks)** dos dados (n√£o valores).
    
- Mede **rela√ß√£o mon√≥tona** (n√£o necessariamente linear).
    
- **Mais robusta a outliers**.
    

---

## üîÅ **6. Valida√ß√£o e Conjuntos de Dados**

### üß© Divis√£o treino/teste:

- **Treino:** ajustar o modelo.
    
- **Teste:** medir desempenho em dados novos.
    
- Evita _overfitting_ (modelo ‚Äúmemoriza‚Äù o treino e erra no teste).
    

---

### üîÅ **Valida√ß√£o Cruzada (k-Fold Cross Validation):**

1. Divide o dataset em _k_ partes iguais (folds).
    
2. Treina com k‚àí1 partes e testa com a parte restante.
    
3. Repete k vezes trocando o fold de teste.
    
4. Faz a **m√©dia dos resultados**.
    

**Pseudoc√≥digo:**

```
dividir dados em k partes
para i de 1 at√© k:
    treino = dados - fold_i
    teste = fold_i
    modelo = treinar(treino)
    erro[i] = avaliar(modelo, teste)
mse_final = m√©dia(erro)
```

‚úÖ **Vantagens:**

- Usa todos os dados para treino e teste.
    
- Reduz vi√©s e varia√ß√£o na avalia√ß√£o.
    

---

## ‚ö†Ô∏è **7. Overfitting e Underfitting**

|Conceito|Descri√ß√£o|Sintoma|
|---|---|---|
|**Overfitting**|Modelo se ajusta demais ao treino|Erro baixo no treino, alto no teste|
|**Underfitting**|Modelo muito simples|Erro alto em ambos|

üéØ **Objetivo:** encontrar o equil√≠brio ‚Äî bom desempenho em dados **nunca vistos**.

---

## üßÆ **8. Perceptron (Algoritmo de Classifica√ß√£o)**

### üîπ Estrutura:

- Entradas: ( $x_1, x_2, ..., x_n$ )
    
- Pesos: ( $w_1, w_2, ..., w_n$ )
    
- Vi√©s (bias): ( $b$ )
    
- Sa√≠da:  
$$
	y =  
    \begin{cases}  
    1, & \text{se } (Œ£ w_i x_i + b) > 0 \\
    0, & \text{caso contr√°rio}  
    \end{cases}  

$$

---

### üß© Pseudoc√≥digo:

```
inicializar pesos w_i = 0 e bias b = 0
para √©poca em 1..N:
    para cada amostra (x, y_esperado):
        y_pred = passo(Œ£(w_i * x_i) + b)
        erro = y_esperado - y_pred
        para cada peso w_i:
            w_i = w_i + Œ± * erro * x_i
        b = b + Œ± * erro
```

- **Œ±** ‚Üí taxa de aprendizado (ex: 0.1)

- Atualiza pesos apenas quando h√° erro.
    

---

## üìö **9. Conceitos-Chave para Revisar**

|Conceito|Defini√ß√£o curta|
|---|---|
|**MSE**|Mede erro m√©dio das previs√µes|
|**Z-Score**|Quantos desvios padr√£o o valor est√° da m√©dia|
|**Bias (vi√©s)**|Erro sistem√°tico do modelo|
|**Vari√¢ncia**|Sensibilidade √†s varia√ß√µes do treino|
|**Trade-off Vi√©s-Vari√¢ncia**|Ajustar complexidade para minimizar erro total|
|**Normaliza√ß√£o**|Escalar dados (0‚Äì1) para evitar distor√ß√µes|
|**Outlier**|Valor que foge do padr√£o da distribui√ß√£o|

---

## üßæ Dica Final de Estudo

Priorize entender **o racioc√≠nio por tr√°s dos algoritmos**:

- Por que normalizar?
    
- O que significa ‚Äúerro baixo‚Äù?
    
- Como o modelo aprende com dados?
    

E pratique implementando:

- `LinearRegression()` e `KFold()` do **Scikit-Learn**
    
- `pearsonr()` e `spearmanr()` do **SciPy**
    
- Pequenos datasets como ‚ÄúAdvertising.csv‚Äù para treinar e validar.
