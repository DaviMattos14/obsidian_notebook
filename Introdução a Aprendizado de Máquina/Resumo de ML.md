
# üß† **Resumo para Prova ‚Äì ICP363: Introdu√ß√£o ao Aprendizado de M√°quina**

---

## üèÅ **1. Fundamentos**

### üìå O que √© Aprendizado de M√°quina (ML)?

- Sub√°rea da **Intelig√™ncia Artificial (IA)**.
    
- **Objetivo**: fazer sistemas melhorarem sua performance **com a experi√™ncia (dados)**.
    
- ML aprende **padr√µes** e **faz previs√µes** sem precisar de regras expl√≠citas.
    

### ‚öôÔ∏è Rela√ß√£o entre √°reas:

|√Årea|Descri√ß√£o|
|---|---|
|**IA**|Sistemas inteligentes que simulam comportamento humano.|
|**ML**|Algoritmos que aprendem com dados.|
|**DL (Deep Learning)**|Modelos com v√°rias camadas (redes neurais profundas).|
|**Data Science**|Extra√ß√£o de conhecimento de dados (usa ML, estat√≠stica e minera√ß√£o).|

### üï∞Ô∏è Breve hist√≥rico:

- **Bayes (1763)** ‚Äì probabilidade condicional.
    
- **Markov (1913)** ‚Äì processos estoc√°sticos.
    
- **Perceptron (1957)** ‚Äì primeira rede neural.
    
- **Backpropagation (1986)** ‚Äì aprendizado em redes multicamadas.
    

---

## üìä **2. Tipos de Aprendizado**

### üîπ Supervisionado:

- Dados **rotulados** (x ‚Üí y conhecidos).
    
- O modelo **aprende mapeamento f(x) ‚Üí y**.
    
- Exemplo:
    
    - Regress√£o linear (previs√£o de valores cont√≠nuos)
        
    - Classifica√ß√£o (atribui√ß√£o de r√≥tulos, ex: spam/n√£o spam)
        

**Pseudoc√≥digo b√°sico:**

```
Para cada amostra (x_i, y_i) no conjunto de treino:
    modelo ‚Üê ajustar par√¢metros para minimizar erro entre previs√£o e y_i
```

---

### üîπ N√£o Supervisionado:

- Dados **n√£o rotulados**.
    
- O algoritmo descobre **padr√µes ocultos** (grupos, associa√ß√µes).
    
- Exemplo: _Clustering (agrupamento K-Means)_.
    

---

### üîπ Por Refor√ßo:

- O agente aprende por **recompensa/puni√ß√£o** ao interagir com o ambiente.
    
- Exemplo: jogos, rob√≥tica, controle aut√¥nomo.
    

---

## üß© **3. Tipos de Dados e Pr√©-Processamento**

### üßÆ Tipos de atributos:

|Tipo|Exemplo|Observa√ß√£o|
|---|---|---|
|**Nominal**|Cor (vermelho, azul)|Sem ordem.|
|**Bin√°rio**|Fumante (0/1)|Dois estados.|
|**Ordinal**|Tamanho (P, M, G)|Ordem, sem dist√¢ncia fixa.|
|**Num√©rico**|Idade, peso|Intervalo ou raz√£o.|

---

### ‚öôÔ∏è Etapas de pr√©-processamento:

1. **Limpeza de dados**
    
    - Preencher valores ausentes (m√©dia, mediana, modelo preditivo).
        
    - Remover ru√≠do (m√©todo de _binning_, regress√£o).
        
    - Detectar outliers.
        
2. **Integra√ß√£o de dados**
    
    - Unir dados de m√∫ltiplas fontes, resolvendo duplicatas e conflitos de nomes.
        
3. **Redu√ß√£o de dados**
    
    - Reduzir dimensionalidade (PCA, amostragem, sele√ß√£o de atributos).
        
4. **Transforma√ß√£o de dados**
    
    - Normalizar (ex: [0,1]).
        
    - Discretizar (intervalos, faixas de idade etc.).
        

---

### üßÆ Estat√≠stica b√°sica:

- **M√©dia** (tend√™ncia central)
    
- **Mediana** (valor central)
    
- **Moda** (valor mais frequente)
    
- **Vari√¢ncia** = m√©dia dos desvios¬≤ da m√©dia
    
- **Desvio padr√£o** = ‚àövari√¢ncia
    
- **Z-score** = (valor - m√©dia) / desvio padr√£o ‚Üí mede qu√£o longe est√° da m√©dia.
    

---

## üßÆ **4. Regress√£o Linear**

### üìà Modelo:

$$
y = Œ≤_0 + Œ≤_1x + Œµ  

$$
- ( $Œ≤_0$ ): intercepto (valor de y quando x = 0)
    
- ( $Œ≤_1$ ): inclina√ß√£o (quanto y muda quando x varia 1 unidade)
    
- ( $Œµ$ ): erro (diferen√ßa entre previsto e real)
    

**Pseudoc√≥digo (ajuste por m√≠nimos quadrados):**

```
dados = {(x1, y1), ..., (xn, yn)}

Œ≤1 = Cov(x, y) / Var(x)
Œ≤0 = M√©dia(y) - Œ≤1 * M√©dia(x)

para cada novo x:
    prever y_pred = Œ≤0 + Œ≤1 * x
```

### üìä Avalia√ß√£o:

- **Erro Quadr√°tico M√©dio (MSE)**  
$$
MSE = \frac{1}{n}\sum(y_i - \hat{y_i})^2  
$$
    
- Quanto **menor o MSE**, melhor o ajuste.

---

### üîπ Regress√£o Linear M√∫ltipla:
$$
y = Œ≤_0 + Œ≤_1x_1 + Œ≤_2x_2 + ... + Œ≤_nx_n  

$$
- Representa√ß√£o matricial:  
$$
    \mathbf{y} = XŒ≤ + Œµ  
$$    
- Adiciona uma **coluna de 1‚Äôs** para o intercepto.
    

---

## üîó **5. Correla√ß√£o**

### üìè Correla√ß√£o de Pearson:

- Mede **rela√ß√£o linear** entre vari√°veis.  
$$
r = \frac{Cov(x, y)}{œÉ_x œÉ_y}      
$$
- Varia entre **-1 e 1**.
    
    - r = 1 ‚Üí forte positiva
        
    - r = -1 ‚Üí forte negativa
        
    - r ‚âà 0 ‚Üí sem correla√ß√£o linear
        
- **Sens√≠vel a outliers.**
    

---

### üìà Correla√ß√£o de Spearman:

- Usa **ordem (ranks)** dos dados (n√£o valores).
    
- Mede **rela√ß√£o mon√≥tona** (n√£o necessariamente linear).
    
- **Mais robusta a outliers**.
    

---

## üîÅ **6. Valida√ß√£o e Conjuntos de Dados**

### üß© Divis√£o treino/teste:

- **Treino:** ajustar o modelo.
    
- **Teste:** medir desempenho em dados novos.
    
- Evita _overfitting_ (modelo ‚Äúmemoriza‚Äù o treino e erra no teste).
    

---

### üîÅ **Valida√ß√£o Cruzada (k-Fold Cross Validation):**

1. Divide o dataset em _k_ partes iguais (folds).
    
2. Treina com k‚àí1 partes e testa com a parte restante.
    
3. Repete k vezes trocando o fold de teste.
    
4. Faz a **m√©dia dos resultados**.
    

**Pseudoc√≥digo:**

```
dividir dados em k partes
para i de 1 at√© k:
    treino = dados - fold_i
    teste = fold_i
    modelo = treinar(treino)
    erro[i] = avaliar(modelo, teste)
mse_final = m√©dia(erro)
```

‚úÖ **Vantagens:**

- Usa todos os dados para treino e teste.
    
- Reduz vi√©s e varia√ß√£o na avalia√ß√£o.
    

---

## ‚ö†Ô∏è **7. Overfitting e Underfitting**

|Conceito|Descri√ß√£o|Sintoma|
|---|---|---|
|**Overfitting**|Modelo se ajusta demais ao treino|Erro baixo no treino, alto no teste|
|**Underfitting**|Modelo muito simples|Erro alto em ambos|

üéØ **Objetivo:** encontrar o equil√≠brio ‚Äî bom desempenho em dados **nunca vistos**.

---

## üßÆ **8. Perceptron (Algoritmo de Classifica√ß√£o)**

### üîπ Estrutura:

- Entradas: ( $x_1, x_2, ..., x_n$ )
    
- Pesos: ( $w_1, w_2, ..., w_n$ )
    
- Vi√©s (bias): ( $b$ )
    
- Sa√≠da:  
$$
	y =  
    \begin{cases}  
    1, & \text{se } (Œ£ w_i x_i + b) > 0 \\
    0, & \text{caso contr√°rio}  
    \end{cases}  

$$

---

### üß© Pseudoc√≥digo:

```
inicializar pesos w_i = 0 e bias b = 0
para √©poca em 1..N:
    para cada amostra (x, y_esperado):
        y_pred = passo(Œ£(w_i * x_i) + b)
        erro = y_esperado - y_pred
        para cada peso w_i:
            w_i = w_i + Œ± * erro * x_i
        b = b + Œ± * erro
```

- **Œ±** ‚Üí taxa de aprendizado (ex: 0.1)

- Atualiza pesos apenas quando h√° erro.
    

---

## üìö **9. Conceitos-Chave para Revisar**

|Conceito|Defini√ß√£o curta|
|---|---|
|**MSE**|Mede erro m√©dio das previs√µes|
|**Z-Score**|Quantos desvios padr√£o o valor est√° da m√©dia|
|**Bias (vi√©s)**|Erro sistem√°tico do modelo|
|**Vari√¢ncia**|Sensibilidade √†s varia√ß√µes do treino|
|**Trade-off Vi√©s-Vari√¢ncia**|Ajustar complexidade para minimizar erro total|
|**Normaliza√ß√£o**|Escalar dados (0‚Äì1) para evitar distor√ß√µes|
|**Outlier**|Valor que foge do padr√£o da distribui√ß√£o|

---

## üßæ Dica Final de Estudo

Priorize entender **o racioc√≠nio por tr√°s dos algoritmos**:

- Por que normalizar?
    
- O que significa ‚Äúerro baixo‚Äù?
    
- Como o modelo aprende com dados?
    

E pratique implementando:

- `LinearRegression()` e `KFold()` do **Scikit-Learn**
    
- `pearsonr()` e `spearmanr()` do **SciPy**
    
- Pequenos datasets como ‚ÄúAdvertising.csv‚Äù para treinar e validar.
