# 1. Aprendizado de M√°quina
Aprender √© o processo pelo qual um sistema melhora seu desempenho por meio da experi√™ncia. O Aprendizado de M√°quina (Machine Learning) surge como uma solu√ß√£o para problemas onde √© dif√≠cil antecipar todas as situa√ß√µes poss√≠veis ou programar uma solu√ß√£o passo a passo. As abordagens para o aprendizado incluem:

- **Aprendizado como busca**: Consiste em enumerar um espa√ßo de conceitos e eliminar aqueles que n√£o condizem com os dados observados.
    
- **Aprendizado indutivo**: Foca em extrair informa√ß√µes gerais a partir da observa√ß√£o de um conjunto de casos particulares. Um exemplo hist√≥rico √© como as observa√ß√µes de Tycho Brahe permitiram a Johannes Kepler formular suas leis da mec√¢nica celeste.
    
### O Papel dos Dados

Os dados s√£o a base para o treinamento de programas de aprendizado de m√°quina. O desenvolvimento de um sistema de ML segue etapas como a defini√ß√£o do problema, coleta e prepara√ß√£o dos dados, treinamento e avalia√ß√£o do modelo.

Contudo, a coleta de dados apresenta desafios:

- **Desbalanceamento**: Fontes como a Wikipedia possuem uma distribui√ß√£o de t√≥picos desigual, com maior concentra√ß√£o em √°reas como Esportes, M√∫sica e Pol√≠tica.
    
- **Falta de Diversidade**: Os dados frequentemente sub-representam diversas culturas, geografias e grupos √©tnicos , privilegiando pontos de vista predominantes. O acesso √† internet, por exemplo, √© maior entre jovens e em pa√≠ses desenvolvidos.
    
- **Dados no Brasil**: Embora o acesso √† internet atinja 80% dos domic√≠lios, h√° uma disparidade social: 100% da classe A est√° conectada, contra 60% das classes D e E.
### Rela√ß√£o com Outras √Åreas

O documento posiciona o Aprendizado de M√°quina dentro de um contexto mais amplo:

- **Intelig√™ncia Artificial (IA)**: √â a √°rea mais ampla, focada na constru√ß√£o de sistemas inteligentes que se comportam como humanos.
    
- **Aprendizado de M√°quina (ML)**: √â uma sub√°rea da IA que desenvolve algoritmos capazes de aprender.
    
- **Aprendizado Profundo (Deep Learning)**: Uma sub√°rea do ML que utiliza modelos com m√∫ltiplas camadas de processamento para aprender representa√ß√µes de dados em v√°rios n√≠veis de abstra√ß√£o.
    
- **Ci√™ncia de Dados e Minera√ß√£o de Dados**: A Ci√™ncia de Dados estuda a extra√ß√£o de conhecimento a partir de dados, utilizando t√©cnicas de ML , enquanto a Minera√ß√£o de Dados foca na aplica√ß√£o de algoritmos para extrair padr√µes de conjuntos de dados.
# 2. Perceptron

Ele √© o **modelo mais simples de rede neural** e foi o ponto de partida para o desenvolvimento do **aprendizado supervisionado**.

- Objetivo: **Classificar** dados em duas classes (ex: 0 ou 1, -1 ou +1).
    
- Tipo: **Aprendizado supervisionado (classifica√ß√£o bin√°ria)**.
    
- Baseia-se em **combinar entradas ponderadas por pesos** e aplicar uma **fun√ß√£o de ativa√ß√£o**.

O Perceptron representa **um neur√¥nio artificial** com

| Componente                     | Descri√ß√£o                                            |
| ------------------------------ | ---------------------------------------------------- |
| **Entradas (x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)** | Atributos ou vari√°veis de entrada.                   |
| **Pesos (w‚ÇÅ, w‚ÇÇ, ..., w‚Çô)**    | Par√¢metros ajust√°veis (import√¢ncia de cada entrada). |
| **Vi√©s (bias, b)**             | Constante que desloca o limiar da decis√£o.           |
| **Soma Ponderada (z)**         | $z = \sum_{i=1}^{n} (w_i \cdot x_i) + b$             |
| **Fun√ß√£o de Ativa√ß√£o (f)**     | Converte ( z ) em sa√≠da bin√°ria (0 ou 1).            |
Sa√≠da:  
$$
	y =  
    \begin{cases}  
    1, & \text{se } (Œ£_{i=1} w_i x_i + b) > 0 \\
    0, & \text{caso contr√°rio}  
    \end{cases}  
$$

### üß© Pseudoc√≥digo:

```
Entrada: dados de treino {(x‚ÇÅ, y‚ÇÅ), ..., (x‚Çô, y‚Çô)}
inicializar pesos w_i = 0 e bias b = 0
Definir taxa de aprendizado Œ± (ex: 0.1)

para √©poca em 1..N:
    para cada amostra (x, y_esperado):
        y_pred = ativacao(Œ£(w_i * x_i) + b)
        erro = y_esperado - y_pred
        para cada peso w_i:
            w_i = w_i + Œ± * erro * x_i
        b = b + Œ± * erro
```

**Fun√ß√£o ativa√ß√£o:** retorna 1 se entrada > 0, sen√£o 0.
- **Œ±** ‚Üí taxa de aprendizado (ex: 0.1)
- Atualiza pesos apenas quando h√° erro.
O Perceptron busca **coeficientes (pesos)** que satisfa√ßam:

$$
y_i (w \cdot x_i + b) > 0
$$
para todas as amostras corretamente classificadas.

Se o conjunto for **linearmente separ√°vel**, o Perceptron **converge** (ou seja, encontra pesos corretos).

Se **n√£o for separ√°vel**, ele **n√£o converge** (fica oscilando).

## Representa√ß√£o Geom√©trica

A fronteira de decis√£o √© dada por:

$$
w_1x_1 + w_2x_2 + ... + w_nx_n + b = 0
$$
- Pontos acima ‚Üí classe 1
- Pontos abaixo ‚Üí classe 0

---

## Limita√ß√µes

| Limita√ß√£o                                                  | Explica√ß√£o                                        |
| ---------------------------------------------------------- | ------------------------------------------------- |
| **Somente separ√°vel linearmente**                          | N√£o funciona para padr√µes n√£o lineares (ex: XOR). |
| **Converg√™ncia garantida apenas se linearmente separ√°vel** | Caso contr√°rio, entra em loop.                    |
| **Fun√ß√£o de ativa√ß√£o simples**                             | Apenas degrau; n√£o lida com probabilidades.       |

---

## Vers√£o Vetorial (Forma Compacta)

$$
\begin{matrix}
\mathbf{w} \leftarrow \mathbf{w} + Œ± (y - \hat{y}) \mathbf{x} \\  b \leftarrow b + Œ± (y - \hat{y})
\end{matrix}
$$

- $\mathbf{w}$: vetor de pesos
- $\mathbf{x}$: vetor de entrada
- $y$: r√≥tulo real
- $\hat{y}$‚Äã: previs√£o
## üí° **Dica para Prova**

Lembre-se:
- O perceptron **n√£o ‚Äúentende‚Äù padr√µes curvos** ‚Äî s√≥ retas/planos.
- **Erro = esperado - previsto**
- **Atualiza pesos somente se erra**
- **Bias desloca a fronteira de decis√£o** (n√£o precisa passar pela origem).

#  3. Tipos de Aprendizado

### üîπ Supervisionado:

- Dados **rotulados** (x ‚Üí y conhecidos).
- O modelo **aprende mapeamento f(x) ‚Üí y**.

- Exemplo:
    - Regress√£o linear (previs√£o de valores cont√≠nuos)
    - Classifica√ß√£o (atribui√ß√£o de r√≥tulos, ex: spam/n√£o spam)

#### Como funciona

1. Fornecemos **dados de treino** com pares (entrada, sa√≠da):
$$
  D = \{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\}  
$$
    
2. O modelo aprende **a rela√ß√£o entre x e y** ajustando seus par√¢metros.
3. Depois √© testado em **dados novos** (sem r√≥tulo) para verificar se generalizou bem.
 #### Tipos principais
- **Regress√£o:** Usada para prever valores cont√≠nuos.
- **Classifica√ß√£o:** Utiliza um algoritmo para atribuir dados a categorias espec√≠ficas.

‚ö†Ô∏è Cuidados
- Dividir dataset em **treino e teste**.
- Evitar **overfitting** (memorizar dados).
- Avaliar com m√©tricas adequadas (MSE, acur√°cia, precis√£o, recall...).

---

### üîπ N√£o Supervisionado:

Neste tipo, **os dados n√£o t√™m r√≥tulos** ‚Äî o modelo tenta **descobrir padr√µes, grupos ou estruturas ocultas** nos dados. N√£o h√° ‚Äúresposta correta‚Äù para comparar.

- Dados **n√£o rotulados**.
- O algoritmo descobre **padr√µes ocultos** (grupos, associa√ß√µes).

 Objetivo
- Encontrar **rela√ß√µes internas** entre os dados.
- Reduzir dimensionalidade, agrupar exemplos similares ou identificar outliers.
- Exemplo: _Clustering (agrupamento K-Means)_.

‚ö†Ô∏è Limita√ß√µes
- Dif√≠cil avaliar se o agrupamento est√° ‚Äúcorreto‚Äù.
- Requer interpreta√ß√£o humana posterior.
---

### üîπ Por Refor√ßo:

- O agente aprende por **recompensa/puni√ß√£o** ao interagir com o ambiente.
- Exemplo: jogos, rob√≥tica, controle aut√¥nomo.
    
---

# 4. Modelos Param√©tricos vs. N√£o Param√©tricos

- **Modelos Param√©tricos:** Resumem os dados com um conjunto de par√¢metros de tamanho fixo, independentemente do n√∫mero de exemplos. Exemplos incluem Regress√£o Linear e Perceptron.
    
    - **Vantagens:** S√£o mais f√°ceis de interpretar, mais r√°pidos e n√£o exigem muitos dados.
    - **Desvantagens:** S√£o muito dependentes da fun√ß√£o escolhida e mais adequados para problemas simples.
        
- **Modelos N√£o Param√©tricos:** N√£o podem ser caracterizados por um conjunto limitado de par√¢metros. Exemplos incluem √°rvores de decis√£o, redes neurais e SVM.
    
    - **Vantagens:** S√£o mais flex√≠veis, n√£o fazem suposi√ß√µes sobre a fun√ß√£o subjacente e possuem alta performance.
    - **Desvantagens:** Requerem mais dados, s√£o mais lentos para treinar e t√™m maior risco de _overfitting_.
---

# 5. Tipos de Dados

## Dados Estruturados 

S√£o dados organizados, com informa√ß√µes representadas por atributos (features) e seus valores, geralmente armazenados em bancos de dados ou planilhas. Os tipos de atributos podem ser:

- **Categ√≥ricos/Nominais:** Valores que representam categorias (ex: cor do cabelo).
- **Booleano:** Apenas dois valores (verdadeiro/falso).
- **Ordinal:** Valores que representam uma escala (ex: n√≠vel de satisfa√ß√£o).
- **Num√©ricos:** Valores inteiros ou reais. 

## Dados N√£o Estruturados 
S√£o compostos por diferentes tipos de dados combinados, como textos e imagens.

- **Prepara√ß√£o de Dados:** Textos podem ser convertidos em representa√ß√µes num√©ricas (vetores) para capturar rela√ß√µes sem√¢nticas, como no exemplo `(rei - homem) + mulher = rainha`.
- **Dados de Imagem:** Uma imagem pode ser vista como uma matriz de pixels. Cada pixel √© representado por um valor num√©rico, seja em escala de cinza (um inteiro de 0 a 255) ou RGB (tr√™s inteiros, um para cada cor).

# 6. M√©tricas de Avalia√ß√£o para Modelos

Treinar um modelo (regress√£o, classifica√ß√£o etc.) n√£o √© o suficiente.  
Precisamos **quantificar seu desempenho** ‚Äî ou seja, **medir o erro ou acerto das previs√µes**.

- **Objetivo:** saber se o modelo **generaliza bem** para dados novos.
- **Problema comum:** _Overfitting_ (modelo ‚Äúdecorou‚Äù o treino) ou _Underfitting_ (modelo muito simples)

## Matriz de confus√£o
![[Pasted image 20251008193718.png]]
- **Verdadeiro Positivo (VP):** O modelo previu "positivo" e o valor real era "positivo".
- **Falso Positivo (FP):** O modelo previu "positivo", mas o valor real era "negativo".
- **Falso Negativo (FN):** O modelo previu "negativo", mas o valor real era "positivo".
- **Verdadeiro Negativo (VN):** O modelo previu "negativo" e o valor real era "negativo".

## Acur√°cia
Percentual de acertos totais do modelo. 
Boa quando as classes est√£o **equilibradas**
$$
\text{Acur√°cia }=\frac{VP+VN}{VP+VN+FP+FN}
$$
‚Äã
## Revoca√ß√£o (Recall)
De todos os casos que eram realmente "positivos", quantos o modelo conseguiu identificar?
Alta sensibilidade ‚Üí poucos falsos negativos.
$$
\text{Recall}=\frac{VP}{VP+FN}‚Äã
$$
## Precis√£o
Das vezes que o modelo previu "positivo", quantas ele acertou?
Alta precis√£o ‚Üí poucos falsos positivos.
$$
\text{Precision}=\frac{VP}{VP+FP}‚Äã
$$
## F1 - Score
M√©dia harm√¥nica entre precis√£o e revoca√ß√£o, √∫til para balancear o impacto de falsos positivos e falsos negativos
Boa quando h√° **classes desbalanceadas**.
$$
\text{F1}=2\times \frac{\text{Precis√£o}\times \text{Recall}}{\text{Precis√£o} + \text{Recall}}‚Äã
$$

| M√©trica      | Melhor em...                                    | Exemplo                              |
| ------------ | ----------------------------------------------- | ------------------------------------ |
| **Acur√°cia** | Bases **balanceadas**                           | Spam vs. n√£o spam                    |
| **Precis√£o** | Custo alto de **falsos positivos**              | Biometria banc√°ria                   |
| **Recall**   | Custo alto de **falsos negativos**              | Diagn√≥stico de c√¢ncer                |
| **F1**       | Bases **desbalanceadas** e com erros sim√©tricos | An√°lise de sentimentos em e-commerce |


# 7. Tipos de Dados e Pr√©-Processamento

### Tipos de atributos:

| Tipo         | Exemplo              | Observa√ß√£o                 |
| ------------ | -------------------- | -------------------------- |
| **Nominal**  | Cor (vermelho, azul) | Sem ordem.                 |
| **Bin√°rio**  | Fumante (0/1)        | Dois estados.              |
| **Ordinal**  | Tamanho (P, M, G)    | Ordem, sem dist√¢ncia fixa. |
| **Num√©rico** | Idade, peso          | Intervalo ou raz√£o.        |

---
### Etapas de pr√©-processamento:

1. **Limpeza de dados**
    - Preencher valores ausentes (m√©dia, mediana, modelo preditivo).
    - Remover ru√≠do (m√©todo de _binning_, regress√£o).
    - Detectar outliers.
        
2. **Integra√ß√£o de dados**
    - Unir dados de m√∫ltiplas fontes, resolvendo duplicatas e conflitos de nomes.
        
3. **Redu√ß√£o de dados**
    - Reduzir dimensionalidade (PCA, amostragem, sele√ß√£o de atributos).
        
4. **Transforma√ß√£o de dados**
    - Normalizar (ex: [0,1]).
    - Discretizar (intervalos, faixas de idade etc.).
        
---

### üßÆ Estat√≠stica b√°sica:

#### Medidas de Posi√ß√£o: 
medem a localiza√ß√£o do meio ou centro de uma distribui√ß√£o;

- **M√©dia** (tend√™ncia central)
$$
    \frac{\sum\limits x_i}{n}
$$
sens√≠vel a valores extremos (outliers).

- **Mediana** (valor central)
$$
    \text{mediana }(x) =
 \begin{cases}
 \text{x}_{\frac{n+1}{2}} & \text{se n for √≠mpar} \\
\frac{(\text{x}_{\frac{n}{2}} + \text{x}_{\frac{n+1}{2}})}{2} & \text{se n for par}
 \end{cases}   
$$
para dados assim√©tricos, esta √© a melhor medida.

- **Moda** (valor mais frequente)
#### Medidas de dispers√£o: 
s√£o utilizadas para que possamos saber qual o grau de varia√ß√£o dos nossos dados

- **Quartis**:
	Dividem os dados ordenados em quatro partes iguais. O primeiro quartil (Q1) corresponde ao percentil 25, o segundo (Q2) √© a mediana (percentil 50), e o terceiro (Q3) √© o percentil 75
	
	**Intervalo Interquart√≠lico (IQR):** √â a diferen√ßa entre o terceiro e o primeiro quartil ($IQR=Q3‚àíQ1$), representando a dispers√£o dos 50% centrais dos dados.

	Como calcular os quartis:
$$
\begin{matrix} 
i=(N-1)\cdot q+1
\\
P_{p}=x_{[i]}+(i-[i])\cdot(x_{[i]+1}-x_{[i]})
\end{matrix}
$$
onde:
- $i$ = √≠ndice
- $N$ = N√∫mero de elementos
- $q$ = percentil (0.25, 0.50, 0.75)
- Pp = Valor do percentil (25, 50, 75)
- $[i]$ = valor inteiro de $i$
- $x_{[i]}$ = Elemento na posi√ß√£o $i$

	Como calcular os limites:
	-  $X_i > LS \text{ (Limite Superior)}$, para $LS=Q_3 + 1.5\times(Q_3-Q_1)$
	- $X_i < LI \text{ (Limite Inferior)}$, para $LI=Q_1 - 1.5\times(Q_3-Q_1)$

- **Vari√¢ncia** $\sigma$= m√©dia dos desvios¬≤ da m√©dia
    $$
    \frac{1}{2}\sum\limits(x_i-\overline{x}_i)^2
$$
- **Desvio padr√£o** = $\sqrt{\sigma}$
    Mede o qu√£o distantes os valores est√£o da m√©dia
- **Z-score** = (valor - m√©dia) / desvio padr√£o ‚Üí mede qu√£o longe est√° da m√©dia.
    $$
    \frac{x-\overline{x}}{\sigma}
$$
# 8. Limpeza de Dados
## **Limpeza de Dados**

Etapa cr√≠tica para eliminar **ru√≠do, erros e inconsist√™ncias** nos dados.
### üî∏ Problemas comuns:

- **Valores ausentes (missing values)**  
- **Outliers (valores at√≠picos)**  
- **Erros de digita√ß√£o / duplica√ß√£o**  

| M√©todo                               | Descri√ß√£o                                            |
| ------------------------------------ | ---------------------------------------------------- |
| **Remo√ß√£o**                          | Excluir linhas/colunas com muitos valores nulos.     |
| **Imputa√ß√£o por m√©dia/mediana/moda** | Substituir valor ausente por uma medida estat√≠stica. |
| **Modelos preditivos**               | Usar outro modelo para prever o valor ausente.       |
# 9. Transforma√ß√£o de Dados
## Escalonamento de Dados Num√©ricos
### Normaliza√ß√£o
Escala os valores para um **intervalo padr√£o [0,1]**.
$$
x'=\frac{x-x_{min}}{x_{max}-x_{min}}
$$
### Padroniza√ß√£o
Converte dados para **m√©dia = 0 e desvio padr√£o = 1**.
$$
x'=\frac{x-\overline{x}}{\sigma}
$$
## Classifica√ß√£o de Dados Categ√≥ricos
| T√©cnica              | Descri√ß√£o                                                                                   | Exemplo                                         |
| -------------------- | ------------------------------------------------------------------------------------------- | ----------------------------------------------- |
| **Label Encoding**   | Cada categoria recebe um n√∫mero inteiro.                                                    | ‚ÄúAzul‚Äù=0, ‚ÄúVerde‚Äù=1, ‚ÄúVermelho‚Äù=2               |
| **One-Hot Encoding** | Cria colunas bin√°rias (0/1) para cada categoria.                                            | ‚ÄúAzul‚Äù ‚Üí [1,0,0]; ‚ÄúVerde‚Äù ‚Üí [0,1,0]             |
| Vari√°vel dummy       | Semelhante ao One-Hot, mas representa C categorias com C-1 vari√°veis, evitando redund√¢ncia. | 'verde'=[1,0]<br>'branco'=[0,1]<br>'azul'=[0,0] |
# 10. Escolha de Modelos
Para um determinado conjunto de dados, m√∫ltiplos algoritmos de aprendizado de m√°quina podem ser aplicados, e n√£o existe um m√©todo universalmente superior a todos os outros. O desempenho de cada algoritmo depende da base de dados utilizada. Portanto, √© crucial utilizar crit√©rios de avalia√ß√£o robustos para selecionar o modelo mais adequado para o problema.

Para avaliar o desempenho de um modelo, especialmente em tarefas de regress√£o, a medida mais comum √© o **Erro Quadr√°tico M√©dio (MSE - Mean Squared Error)**. 

Ele calcula a m√©dia dos quadrados das diferen√ßas entre os valores reais ($y_i$) e os valores previstos pelo modelo $\hat{f}(x_i)$.
$$
MSE=\frac{1}{n}\sum\limits(y_i-\hat{f}(x_i))^2
$$
para Teste e Treinamento.

onde $\hat{f}(x_i)$ √© a previs√£o que $\hat{f}$ da para i-√©sima observa√ß√£o
- MSE ser√° **pequeno** se as respostas previstas forem muito pr√≥ximas das respostas verdadeiras, 
- MSE ser√° **grande** se para algumas das observa√ß√µes, as respostas previstas e verdadeiras diferirem substancialmente.

O **melhor modelo** √© aquele que minimiza o erro de teste esperado.
## Overfitting

Ocorre quando um modelo se ajusta de forma t√£o espec√≠fica aos dados de treinamento que "memoriza" suas particularidades, incluindo ru√≠dos. Isso resulta em um baixo erro de treinamento, mas um alto erro de teste, pois o modelo perde a capacidade de generalizar para novos dados

## Trade-off Vi√©s-Vari√¢ncia 

O erro de teste esperado pode ser decomposto em tr√™s componentes:

1. **Vi√©s (Bias):** O erro introduzido ao usar um modelo simples para aproximar um problema complexo. Modelos mais flex√≠veis geralmente t√™m um vi√©s menor.
2. **Vari√¢ncia (Variance):** A quantidade que o modelo mudaria se fosse treinado com um conjunto de dados diferente. Modelos mais flex√≠veis tendem a ter uma vari√¢ncia maior.
3. **Erro Irredut√≠vel (ru√≠do):** Um erro inerente aos dados, que n√£o pode ser eliminado por nenhum modelo.
descreve a rela√ß√£o inversa entre esses dois componentes: ao aumentar a flexibilidade de um modelo, o vi√©s tende a diminuir, mas a vari√¢ncia tende a aumentar. O desafio √© encontrar um equil√≠brio que minimize o erro total de teste, encontrando um m√©todo com baixo vi√©s e baixa vari√¢ncia

# 11. K Vizinhos Mais Pr√≥ximos - KNN

**Ideia principal:** classificar uma nova amostra com base nos r√≥tulos de suas K amostras mais pr√≥ximas no conjunto de treinamento.
    
- **Caracter√≠sticas:**
    - Algoritmo supervisionado e n√£o param√©trico.
    - M√©todo ‚Äúpregui√ßoso‚Äù: n√£o h√° fase de treinamento; a previs√£o √© feita por compara√ß√£o direta.
        
- **Pr√©-processamento:**
    - Normaliza√ß√£o dos atributos (escala [0,1]).
    - Tratamento de dados ausentes (remo√ß√£o ou imputa√ß√£o).

**Funcionamento:** Para uma nova inst√¢ncia, o algoritmo calcula a dist√¢ncia (geralmente euclidiana) para todas as inst√¢ncias do conjunto de treinamento, identifica os K mais pr√≥ximos e atribui o r√≥tulo da classe majorit√°ria entre eles

- **M√©tricas de dist√¢ncia:** geralmente usa-se a **dist√¢ncia euclidiana**.
$$
d(x,y)=\sqrt{\sum\limits_{i=1}^n(y_i-x_i)^2}
$$
- **Escolha do K:**
    - K pequeno ‚Üí modelo inst√°vel, Apenas objetos muito parecidos s√£o considerados
    - K Grande ‚Üí Vizinhos podem ser muito diferentes, Predi√ß√£o tendenciosa para a classe majorit√°ria
    - Para classes pares, recomenda-se K √≠mpar.
# 12. Conjunto de Treinamento e Teste

Para evitar o _overfitting_ e obter uma avalia√ß√£o de desempenho mais confi√°vel, o conjunto de dados original deve ser dividido. A abordagem mais simples √© a **divis√£o em treino e teste**, usando, por exemplo, 80% dos dados para treinamento e 20% para teste, de forma aleat√≥ria.

Quando n√£o h√° dados de teste suficientes, usamos **t√©cnicas de reamostragem** para estimar o desempenho do modelo

## T√©cnicas de Reamostragem:

### K-Fold Cross-Validation

√â uma das t√©cnicas mais comuns de valida√ß√£o de modelos.

**Como funciona:**

1. O conjunto de dados √© dividido em **K partes (folds)** aproximadamente do mesmo tamanho.
2. O modelo √© treinado em **K‚àí1 folds** e testado no **fold restante**.
3. Repete-se o processo **K vezes**, trocando o fold de teste a cada rodada.
4. O erro final √© a **m√©dia dos K erros**.
    
**Vantagens:**
- Usa todos os dados para treinamento e teste em momentos diferentes.
- Reduz a vari√¢ncia da estimativa do erro.
- K t√≠pico: **5 ou 10**.

**Desvantagem:**
- Pode ser **computacionalmente custoso** para modelos grandes.
### Stratified K-Fold Cross-Validation

√â uma **varia√ß√£o do K-Fold** usada especialmente em **problemas de classifica√ß√£o**.

**Diferen√ßa principal:**

- Garante que cada fold preserve a **propor√ß√£o de classes** do conjunto original.  
    Exemplo: se 30% das amostras s√£o da classe ‚ÄúA‚Äù e 70% da classe ‚ÄúB‚Äù, cada fold manter√° aproximadamente essa propor√ß√£o.

**Vantagem:**

- Evita vieses causados por desequil√≠brio entre as classes em cada divis√£o.
- Fornece estimativas de erro mais realistas em conjuntos desbalanceados.

### Bootstrap

Gera m√∫ltiplos conjuntos de treinamento por amostragem com reposi√ß√£o do conjunto de dados original

**Como funciona:**

1. Gera-se um **novo conjunto de treinamento** de mesmo tamanho do original, **amostrando com reposi√ß√£o** (alguns exemplos aparecem v√°rias vezes, outros podem n√£o aparecer).
2. O modelo √© treinado nesse novo conjunto.
3. As observa√ß√µes **n√£o inclu√≠das** (aproximadamente 36,8% dos dados) formam o **conjunto de teste** (‚Äúout-of-bag‚Äù samples).
4. O processo √© repetido v√°rias vezes (ex.: 1000 vezes) e os erros s√£o **m√©dios**.
    
**Vantagens:**

- Boa estimativa de variabilidade (intervalos de confian√ßa).
- √ötil quando o conjunto de dados √© pequeno.

**Desvantagens:**

- Pode superestimar o desempenho se o modelo for muito sens√≠vel a amostras espec√≠ficas.

# 13 **. Regress√£o Linear**

A regress√£o linear √© um dos modelos mais fundamentais e amplamente utilizados no aprendizado de m√°quina supervisionado, especialmente em **problemas de predi√ß√£o cont√≠nua**.
### Objetivo:

Modelar a rela√ß√£o entre uma **vari√°vel dependente (y)** e uma ou mais **vari√°veis independentes (x‚ÇÅ, x‚ÇÇ, ‚Ä¶, x‚Çô)**, ajustando uma fun√ß√£o linear aos dados observados.
### Regress√£o Linear Simples:

$$
y = Œ≤_0 + Œ≤_1x + Œµ  

$$
- ( $Œ≤_0$ ): intercepto (valor de y quando x = 0) - coeficiente linear
- ( $Œ≤_1$ ): inclina√ß√£o (quanto y muda quando x varia 1 unidade) - coeficiente angular
- ( $Œµ$ ): erro (diferen√ßa entre previsto e real)

A ideia √© encontrar os valores de Œ≤‚ÇÄ e Œ≤‚ÇÅ que minimizam o **erro quadr√°tico m√©dio (MSE)** entre as previs√µes e os valores reais

### M√≠nimos Quadrados

Para encontrar os melhores valores para $Œ≤^‚Äã0‚Äã$ e $Œ≤^‚Äã1$‚Äã, o m√©todo mais comum √© o dos **m√≠nimos quadrados**. Ele busca minimizar a soma dos quadrados dos res√≠duos (erros), que √© a diferen√ßa entre os valores reais ($y_i$‚Äã) e os valores previstos pela reta ($y_{i_{previsto}}$‚Äã‚Äã). Essa soma √© conhecida como **Soma dos Quadrados dos Res√≠duos (RSS - Residual Sum of Squares)**.
$$
RSS = \sum\limits(y_i-y_{previsto})^2=\sum\limits^n_{i=1}(y-(\hat{\beta_1}x_i+\hat{\beta_0}))^2
$$
Derivando RSS em fun√ß√£o de $\hat{\beta_1}$ e $\hat{\beta_0}$ e igualando a zero, chegamos nas seguintes f√≥rmulas fechadas:
$$
\frac{\partial J(\hat{\beta_0},\hat{\beta_0})}{\partial \hat{\beta_1}} = \hat{\beta_1}\sum x_i + \hat{\beta_0}\cdot n = \sum y_i
$$
$$
\frac{\partial J(\hat{\beta_0},\hat{\beta_1})}{\partial \hat{\beta_1}}= \hat{\beta_1}\sum x_i^2 +\hat{\beta_0}\sum x_i = \sum x_iy_i
$$

### Regress√£o Linear Multipla:
Quando h√° mais de uma vari√°vel independente:

$$
y = Œ≤_0 + Œ≤_1x_1 + Œ≤_2x_2 + ‚Ä¶ + Œ≤_nx_n + Œµ
$$

### Forma matricial:

$$
\mathbf{y} = \mathbf{XŒ≤} + \mathbf{Œµ}
$$
Onde:
- **X** √© a matriz de entradas (com n amostras e p vari√°veis);
- **Œ≤** √© o vetor de coeficientes;
- **y** √© o vetor de sa√≠das.
### Estima√ß√£o dos par√¢metros:

$$
\hat{Œ≤} = (X^TX)^{-1}X^Ty
$$

Esse vetor **Œ≤ÃÇ** fornece os coeficientes que minimizam o erro de previs√£o.

**Pseudoc√≥digo (ajuste por m√≠nimos quadrados):**

```
dados = {(x1, y1), ..., (xn, yn)}

Œ≤1 = Cov(x, y) / Var(x)
Œ≤0 = M√©dia(y) - Œ≤1 * M√©dia(x)

para cada novo x:
    prever y_pred = Œ≤0 + Œ≤1 * x
```


### Correla√ß√£o 

Nem todas as vari√°veis de entrada contribuem igualmente para a previs√£o da vari√°vel de sa√≠da. A **sele√ß√£o de features** √© o processo de escolher os atributos mais relevantes, o que pode diminuir o _overfitting_, melhorar o desempenho e reduzir o tempo de treinamento. Uma forma de fazer isso √© atrav√©s da an√°lise de correla√ß√£o**

### üìè Correla√ß√£o de Pearson:

- Mede **rela√ß√£o linear** entre vari√°veis.  
$$
r = \frac{Cov(x, y)}{œÉ_x œÉ_y}   
$$
![[Pasted image 20251008230007.png]]
- Varia entre **-1 e 1**.
    
	- r = 1 ‚Üí forte positiva
    - r = -1 ‚Üí forte negativa
    - r ‚âà 0 ‚Üí sem correla√ß√£o linear
        
- **Sens√≠vel a outliers.**

**Interpreta√ß√£o**:

- **Correla√ß√£o alta entre features** ‚Üí multicolinearidade, o que pode distorcer os coeficientes Œ≤;
- **Correla√ß√£o alta entre uma feature e o alvo (y)** ‚Üí boa candidata para o modelo.

---

### üìà Correla√ß√£o de Spearman:

- Usa **ordem (ranks)** dos dados (n√£o valores).
- Mede **rela√ß√£o mon√≥tona** (n√£o necessariamente linear).
- **Mais robusta a outliers**.

|Valor de œÅ|Interpreta√ß√£o|
|---|---|
|**+1**|Correla√ß√£o monot√¥nica **positiva perfeita** ‚Äì √† medida que X aumenta, Y sempre aumenta.|
|**0**|**Nenhuma correla√ß√£o monot√¥nica** ‚Äì n√£o h√° tend√™ncia consistente.|
|**‚Äì1**|Correla√ß√£o monot√¥nica **negativa perfeita** ‚Äì √† medida que X aumenta, Y sempre diminui.|

Use Spearman quando:

- Os **dados n√£o seguem distribui√ß√£o normal** (violam a suposi√ß√£o de normalidade);
    
- As **rela√ß√µes entre as vari√°veis s√£o monot√¥nicas**, mas **n√£o lineares**;
	    Uma rela√ß√£o √© **monot√¥nica** se, √† medida que uma vari√°vel cresce, a outra **sempre cresce** ou **sempre decresce**, mas n√£o necessariamente em linha reta.
	Exemplo:
	- ‚úÖ Monot√¥nica: √† medida que a temperatura aumenta, o consumo de sorvete aumenta (n√£o precisa ser linear).
	- ‚ùå N√£o monot√¥nica: √† medida que o tempo aumenta, a produtividade sobe at√© certo ponto e depois cai (rela√ß√£o em forma de ‚ÄúU‚Äù).

- Os dados s√£o **ordinais** (valores representando posi√ß√µes, classifica√ß√µes ou ranqueamentos);
    
- H√° **outliers**, que podem distorcer a correla√ß√£o de Pearson.
---
---
### üîÅ **Valida√ß√£o Cruzada (k-Fold Cross Validation):**

1. Divide o dataset em _k_ partes iguais (folds).
    
2. Treina com k‚àí1 partes e testa com a parte restante.
    
3. Repete k vezes trocando o fold de teste.
    
4. Faz a **m√©dia dos resultados**.
    

**Pseudoc√≥digo:**

```
dividir dados em k partes
para i de 1 at√© k:
    treino = dados - fold_i
    teste = fold_i
    modelo = treinar(treino)
    erro[i] = avaliar(modelo, teste)
mse_final = m√©dia(erro)
```

‚úÖ **Vantagens:**

- Usa todos os dados para treino e teste.
    
- Reduz vi√©s e varia√ß√£o na avalia√ß√£o.
    

---

## ‚ö†Ô∏è **7. Overfitting e Underfitting**

|Conceito|Descri√ß√£o|Sintoma|
|---|---|---|
|**Overfitting**|Modelo se ajusta demais ao treino|Erro baixo no treino, alto no teste|
|**Underfitting**|Modelo muito simples|Erro alto em ambos|

üéØ **Objetivo:** encontrar o equil√≠brio ‚Äî bom desempenho em dados **nunca vistos**.

---

## üßÆ **8. Perceptron (Algoritmo de Classifica√ß√£o)**

### üîπ Estrutura:

- Entradas: ( $x_1, x_2, ..., x_n$ )
    
- Pesos: ( $w_1, w_2, ..., w_n$ )
    
- Vi√©s (bias): ( $b$ )
    
- Sa√≠da:  
$$
	y =  
    \begin{cases}  
    1, & \text{se } (Œ£ w_i x_i + b) > 0 \\
    0, & \text{caso contr√°rio}  
    \end{cases}  

$$

---

### üß© Pseudoc√≥digo:

```
inicializar pesos w_i = 0 e bias b = 0
para √©poca em 1..N:
    para cada amostra (x, y_esperado):
        y_pred = passo(Œ£(w_i * x_i) + b)
        erro = y_esperado - y_pred
        para cada peso w_i:
            w_i = w_i + Œ± * erro * x_i
        b = b + Œ± * erro
```

- **Œ±** ‚Üí taxa de aprendizado (ex: 0.1)

- Atualiza pesos apenas quando h√° erro.
    
